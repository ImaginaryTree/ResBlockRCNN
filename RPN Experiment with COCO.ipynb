{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a611509f",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a07617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcdec4",
   "metadata": {},
   "source": [
    "# Class and Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dccd97",
   "metadata": {},
   "source": [
    "### ResVGG16 Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0ddc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pertama definisikan ResidualBlock\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_convs):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential()\n",
    "        \n",
    "        for i in range(num_convs):\n",
    "            input_channels = in_channels if i == 0 else out_channels\n",
    "            self.convs.add_module(f'conv{i+1}', nn.Conv2d(\n",
    "                input_channels, out_channels, kernel_size=3, padding=1))\n",
    "            self.convs.add_module(f'bn{i+1}', nn.BatchNorm2d(out_channels))\n",
    "            self.convs.add_module(f'relu{i+1}', nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.skip = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = self.convs(x)\n",
    "        out = self.pool(out)\n",
    "        out += identity\n",
    "        return nn.functional.relu(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db486277",
   "metadata": {},
   "source": [
    "### Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99d65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kemudian baru definisikan DetectorBackbone yang menggunakan ResidualBlock\n",
    "class DetectorBackbone(nn.Module):\n",
    "    def __init__(self, pretrained_weights=None):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            ResidualBlock(3, 32, 2),\n",
    "            ResidualBlock(32, 64, 2),\n",
    "            ResidualBlock(64, 128, 3),\n",
    "            ResidualBlock(128, 256, 3),\n",
    "            ResidualBlock(256, 256, 3)\n",
    "        )\n",
    "        self.out_channels = 256\n",
    "        \n",
    "        if pretrained_weights:\n",
    "            self.load_pretrained(pretrained_weights)\n",
    "            \n",
    "            # Freeze parameters\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def load_pretrained(self, weight_path):\n",
    "        pretrained_dict = torch.load(weight_path)\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        self.load_state_dict(pretrained_dict, strict=False)\n",
    "        print(f\"Loaded {len(pretrained_dict)}/{len(model_dict)} parameters\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.blocks(x)\n",
    "        return {'0': features}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3f572",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8f5779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17216\\2297163815.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_dict = torch.load(weight_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 126/126 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DetectorBackbone(\n",
       "  (blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (convs): Sequential(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (skip): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 1. Inisialisasi backbone kustom\n",
    "backbone = DetectorBackbone(pretrained_weights='best_model.pth').to(device)\n",
    "backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d57189",
   "metadata": {},
   "source": [
    "###  RPN Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f791499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Konfigurasi Anchor Generator untuk RPN\n",
    "anchor_sizes = ((32, 64, 128, 256, 512),)  # Anchor sizes untuk single feature map\n",
    "aspect_ratios = ((0.5, 1.0, 2.0),)         # Aspect ratios untuk tiap anchor size\n",
    "\n",
    "rpn_anchor_gen = AnchorGenerator(\n",
    "    sizes=anchor_sizes,\n",
    "    aspect_ratios=aspect_ratios\n",
    ")\n",
    "\n",
    "# 3. Konfigurasi ROI Pooling\n",
    "roi_pooler = MultiScaleRoIAlign(\n",
    "    featmap_names=['0'],    # Sesuai dengan key output backbone\n",
    "    output_size=7,          # Ukuran output ROI pooling\n",
    "    sampling_ratio=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6a980",
   "metadata": {},
   "source": [
    "# Merging ResVGG16 Lite With RPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4c3a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(224,), max_size=224, mode='bilinear')\n",
       "  )\n",
       "  (backbone): DetectorBackbone(\n",
       "    (blocks): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convs): Sequential(\n",
       "          (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convs): Sequential(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): ResidualBlock(\n",
       "        (convs): Sequential(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu3): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ResidualBlock(\n",
       "        (convs): Sequential(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu3): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): ResidualBlock(\n",
       "        (convs): Sequential(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu3): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Bangun model Faster R-CNN lengkap\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=2,          # Sesuaikan dengan jumlah kelas (+ background)\n",
    "    rpn_anchor_generator=rpn_anchor_gen,\n",
    "    box_roi_pool=roi_pooler,\n",
    "    min_size=224,           # Sesuaikan dengan ukuran input\n",
    "    max_size=224\n",
    ").to(device)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe1e5bd",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd76bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoTransform:\n",
    "    def __call__(self, image, target):\n",
    "        image = F.to_tensor(image)\n",
    "        return image, target\n",
    "\n",
    "def get_coco_dataset(img_dir, ann_file):\n",
    "    return CocoDetection(\n",
    "        root=img_dir,\n",
    "        annFile=ann_file,\n",
    "        transforms=CocoTransform()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6b5493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_coco_dataset(\n",
    "    img_dir='Dataset/COCODataset/train', \n",
    "    ann_file='Dataset/COCODataset/train/_annotations.coco.json'\n",
    ")\n",
    "\n",
    "val_dataset = get_coco_dataset(\n",
    "    img_dir='Dataset/COCODataset/valid', \n",
    "    ann_file='Dataset/COCODataset/valid/_annotations.coco.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931bb497",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=10,\n",
    "    collate_fn=lambda x: tuple(zip(*x)),  # Menggabungkan batch\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=10,\n",
    "    collate_fn=lambda x: tuple(zip(*x)),  # Menggabungkan batch\n",
    "    shuffle=False  # Tidak perlu shuffle untuk validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de29e6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cd37fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(param, lr=0.0001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408acbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        \n",
    "        processed_targets = []\n",
    "        valid_images = []\n",
    "        for i, target in enumerate(targets):\n",
    "            boxes = []\n",
    "            labels = []\n",
    "            for obj in target:\n",
    "                bbox = obj['bbox']\n",
    "                x, y, w, h = bbox\n",
    "\n",
    "                if w > 0 and h > 0:\n",
    "                    boxes.append([x, y, x + w, y + h])\n",
    "                    labels.append(obj['category_id'])\n",
    "\n",
    "            if boxes:\n",
    "                processed_target = {\n",
    "                    'boxes': torch.tensor(boxes, dtype=torch.float32).to(device),\n",
    "                    'labels': torch.tensor(labels, dtype=torch.int64).to(device)\n",
    "                }\n",
    "                processed_targets.append(processed_target)\n",
    "                valid_images.append(images[i])\n",
    "\n",
    "        if not processed_targets:\n",
    "            continue\n",
    "\n",
    "        images = valid_images\n",
    "\n",
    "        #Forward pass\n",
    "        loss_dict = model(images, processed_targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "820140d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Loss: 0.12288139760494232\n",
      "Epoch [1], Loss: 0.11931924521923065\n",
      "Epoch [2], Loss: 0.08696804195642471\n",
      "Epoch [3], Loss: 0.0859341025352478\n",
      "Epoch [4], Loss: 0.11385681480169296\n",
      "Epoch [5], Loss: 0.08097130060195923\n",
      "Epoch [6], Loss: 0.1056571900844574\n",
      "Epoch [7], Loss: 0.09296265244483948\n",
      "Epoch [8], Loss: 0.09486984461545944\n",
      "Epoch [9], Loss: 0.11524958163499832\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_loss = 9999999\n",
    "for epoch in range(num_epochs):\n",
    "    losses = train_one_epoch(model, optimizer, train_loader, device)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}], Loss: {losses}\")\n",
    "\n",
    "    if losses < best_loss:\n",
    "        best_loss = losses\n",
    "        # Save the model state\n",
    "        torch.save(model.state_dict(), f\"Best_RPNmodel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed647d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
