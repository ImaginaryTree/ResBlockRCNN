{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0eddfab",
   "metadata": {},
   "source": [
    "# this notebook can be used by Conda Environment with cuda-toolkit installed \n",
    "\n",
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60e6daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:03:14.799803Z",
     "iopub.status.busy": "2025-04-25T04:03:14.799440Z",
     "iopub.status.idle": "2025-04-25T04:03:19.325727Z",
     "shell.execute_reply": "2025-04-25T04:03:19.324829Z",
     "shell.execute_reply.started": "2025-04-25T04:03:14.799739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim  # This is the critical import\n",
    "from PIL import Image      # Should show 9.x.x or later\n",
    "from torchsummary import summary\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3360058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA version: 12.4\n",
      "CUDA is available: True\n",
      "Number of CUDA devices: 1\n",
      "Device 0: NVIDIA GeForce GTX 1050\n",
      "Compute capability: (6, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Compute capability: {torch.cuda.get_device_capability(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80213f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:21:46.670179Z",
     "iopub.status.busy": "2025-04-25T04:21:46.669763Z",
     "iopub.status.idle": "2025-04-25T04:21:46.681490Z",
     "shell.execute_reply": "2025-04-25T04:21:46.680473Z",
     "shell.execute_reply.started": "2025-04-25T04:21:46.670153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_convs):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential()\n",
    "        \n",
    "        # Membuat layer konvolusi sesuai jumlah yang ditentukan\n",
    "        for i in range(num_convs):\n",
    "            input_channels = in_channels if i == 0 else out_channels\n",
    "            self.convs.add_module(f'conv{i+1}', nn.Conv2d(\n",
    "                input_channels, out_channels, kernel_size=3, padding=1))\n",
    "            self.convs.add_module(f'bn{i+1}', nn.BatchNorm2d(out_channels))\n",
    "            self.convs.add_module(f'relu{i+1}', nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Skip connection dengan 1x1 conv untuk menyesuaikan dimensi\n",
    "        self.skip = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)  # Proses skip connection\n",
    "        out = self.convs(x)      # Jalur utama melalui konvolusi\n",
    "        out = self.pool(out)     # Pooling setelah konvolusi\n",
    "        out += identity          # Tambahkan skip connection\n",
    "        return F.relu(out)       # Aktivasi akhir\n",
    "\n",
    "class ResidualVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Membangun blok-blok residual sesuai arsitektur VGG16\n",
    "        self.blocks = nn.Sequential(\n",
    "            ResidualBlock(3, 32, 2),       # Blok 1: 2 konvolusi 64 channel\n",
    "            ResidualBlock(32, 64, 2),     # Blok 2: 2 konvolusi 128 channel\n",
    "            ResidualBlock(64, 128, 3),    # Blok 3: 3 konvolusi 256 channel\n",
    "            ResidualBlock(128, 256, 3),    # Blok 4: 3 konvolusi 512 channel\n",
    "            ResidualBlock(256, 256, 3),    # Blok 5: 3 konvolusi 512 channel\n",
    "        )\n",
    "        \n",
    "        # Classifier dengan fully-connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)               # Loloskan melalui semua blok residual\n",
    "        x = torch.flatten(x, 1)          # Flatten feature maps\n",
    "        x = self.classifier(x)           # Loloskan melalui classifier\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7092c94b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:21:51.171807Z",
     "iopub.status.busy": "2025-04-25T04:21:51.171483Z",
     "iopub.status.idle": "2025-04-25T04:21:52.263938Z",
     "shell.execute_reply": "2025-04-25T04:21:52.262988Z",
     "shell.execute_reply.started": "2025-04-25T04:21:51.171784Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             128\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "            Conv2d-3         [-1, 32, 224, 224]             896\n",
      "       BatchNorm2d-4         [-1, 32, 224, 224]              64\n",
      "              ReLU-5         [-1, 32, 224, 224]               0\n",
      "            Conv2d-6         [-1, 32, 224, 224]           9,248\n",
      "       BatchNorm2d-7         [-1, 32, 224, 224]              64\n",
      "              ReLU-8         [-1, 32, 224, 224]               0\n",
      "         MaxPool2d-9         [-1, 32, 112, 112]               0\n",
      "    ResidualBlock-10         [-1, 32, 112, 112]               0\n",
      "           Conv2d-11           [-1, 64, 56, 56]           2,112\n",
      "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
      "           Conv2d-13         [-1, 64, 112, 112]          18,496\n",
      "      BatchNorm2d-14         [-1, 64, 112, 112]             128\n",
      "             ReLU-15         [-1, 64, 112, 112]               0\n",
      "           Conv2d-16         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-17         [-1, 64, 112, 112]             128\n",
      "             ReLU-18         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-19           [-1, 64, 56, 56]               0\n",
      "    ResidualBlock-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21          [-1, 128, 28, 28]           8,320\n",
      "      BatchNorm2d-22          [-1, 128, 28, 28]             256\n",
      "           Conv2d-23          [-1, 128, 56, 56]          73,856\n",
      "      BatchNorm2d-24          [-1, 128, 56, 56]             256\n",
      "             ReLU-25          [-1, 128, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-27          [-1, 128, 56, 56]             256\n",
      "             ReLU-28          [-1, 128, 56, 56]               0\n",
      "           Conv2d-29          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-30          [-1, 128, 56, 56]             256\n",
      "             ReLU-31          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-32          [-1, 128, 28, 28]               0\n",
      "    ResidualBlock-33          [-1, 128, 28, 28]               0\n",
      "           Conv2d-34          [-1, 256, 14, 14]          33,024\n",
      "      BatchNorm2d-35          [-1, 256, 14, 14]             512\n",
      "           Conv2d-36          [-1, 256, 28, 28]         295,168\n",
      "      BatchNorm2d-37          [-1, 256, 28, 28]             512\n",
      "             ReLU-38          [-1, 256, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-40          [-1, 256, 28, 28]             512\n",
      "             ReLU-41          [-1, 256, 28, 28]               0\n",
      "           Conv2d-42          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-43          [-1, 256, 28, 28]             512\n",
      "             ReLU-44          [-1, 256, 28, 28]               0\n",
      "        MaxPool2d-45          [-1, 256, 14, 14]               0\n",
      "    ResidualBlock-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47            [-1, 256, 7, 7]          65,792\n",
      "      BatchNorm2d-48            [-1, 256, 7, 7]             512\n",
      "           Conv2d-49          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-50          [-1, 256, 14, 14]             512\n",
      "             ReLU-51          [-1, 256, 14, 14]               0\n",
      "           Conv2d-52          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-53          [-1, 256, 14, 14]             512\n",
      "             ReLU-54          [-1, 256, 14, 14]               0\n",
      "           Conv2d-55          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-56          [-1, 256, 14, 14]             512\n",
      "             ReLU-57          [-1, 256, 14, 14]               0\n",
      "        MaxPool2d-58            [-1, 256, 7, 7]               0\n",
      "    ResidualBlock-59            [-1, 256, 7, 7]               0\n",
      "           Linear-60                 [-1, 4096]      51,384,320\n",
      "             ReLU-61                 [-1, 4096]               0\n",
      "          Dropout-62                 [-1, 4096]               0\n",
      "           Linear-63                 [-1, 4096]      16,781,312\n",
      "             ReLU-64                 [-1, 4096]               0\n",
      "          Dropout-65                 [-1, 4096]               0\n",
      "           Linear-66                    [-1, 2]           8,194\n",
      "================================================================\n",
      "Total params: 71,969,058\n",
      "Trainable params: 71,969,058\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 178.58\n",
      "Params size (MB): 274.54\n",
      "Estimated Total Size (MB): 453.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResidualVGG16().to(device)  # Your model\n",
    "summary(model, input_size=(3, 224, 224))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56879cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:03:21.494323Z",
     "iopub.status.busy": "2025-04-25T04:03:21.494037Z",
     "iopub.status.idle": "2025-04-25T04:03:21.498572Z",
     "shell.execute_reply": "2025-04-25T04:03:21.497674Z",
     "shell.execute_reply.started": "2025-04-25T04:03:21.494300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Contoh penggunaan\n",
    "# if __name__ == \"__main__\":\n",
    "#     model = ResidualVGG16(num_classes=2)\n",
    "#     input_tensor = torch.randn(1, 3, 224, 224)  # Contoh input\n",
    "#     output = model(input_tensor)\n",
    "#     print(f\"Output shape: {output.shape}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f40000",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a3dc68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:03:21.499661Z",
     "iopub.status.busy": "2025-04-25T04:03:21.499357Z",
     "iopub.status.idle": "2025-04-25T04:03:21.518305Z",
     "shell.execute_reply": "2025-04-25T04:03:21.517248Z",
     "shell.execute_reply.started": "2025-04-25T04:03:21.499640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tumor_dir_path = \"./Dataset/processed/yes\"\n",
    "# no_tumor_dir_path = \"./Dataset/processed/no\"\n",
    "\n",
    "# tumor_image_paths =  os.listdir(tumor_dir_path)\n",
    "# tumor_image_paths = [os.path.join(tumor_dir_path, path) for path in tumor_image_paths]\n",
    "\n",
    "# no_tumor_image_paths =  os.listdir(no_tumor_dir_path)\n",
    "# no_tumor_image_paths = [os.path.join(no_tumor_dir_path, path) for path in no_tumor_image_paths]\n",
    "# no_tumor_image_paths\n",
    "\n",
    "# display(tumor_image_paths, no_tumor_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04113df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:03:21.519530Z",
     "iopub.status.busy": "2025-04-25T04:03:21.519228Z",
     "iopub.status.idle": "2025-04-25T04:03:21.534369Z",
     "shell.execute_reply": "2025-04-25T04:03:21.533495Z",
     "shell.execute_reply.started": "2025-04-25T04:03:21.519507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# dataset_dir_path = '/kaggle/input/brain-tumor-dataset'\n",
    "dataset_dir_path = './Dataset/final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302c8aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:03:21.535671Z",
     "iopub.status.busy": "2025-04-25T04:03:21.535322Z",
     "iopub.status.idle": "2025-04-25T04:03:21.551325Z",
     "shell.execute_reply": "2025-04-25T04:03:21.550423Z",
     "shell.execute_reply.started": "2025-04-25T04:03:21.535641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Update the data preparation function\n",
    "def prepare_data(data_dir='your_dataset'):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "        #                      std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                      std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=f'{data_dir}/train',\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=f'{data_dir}/val',\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e10c55bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:03:21.552836Z",
     "iopub.status.busy": "2025-04-25T04:03:21.552490Z",
     "iopub.status.idle": "2025-04-25T04:03:24.027658Z",
     "shell.execute_reply": "2025-04-25T04:03:24.026717Z",
     "shell.execute_reply.started": "2025-04-25T04:03:21.552804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader = prepare_data(data_dir=dataset_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab71f16b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T04:22:05.413187Z",
     "iopub.status.busy": "2025-04-25T04:22:05.412186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [10/201], Loss: 1.0390\n",
      "Epoch [1/10], Batch [20/201], Loss: 0.8061\n",
      "Epoch [1/10], Batch [30/201], Loss: 1.0868\n",
      "Epoch [1/10], Batch [40/201], Loss: 1.0471\n",
      "Epoch [1/10], Batch [50/201], Loss: 0.8117\n",
      "Epoch [1/10], Batch [60/201], Loss: 0.8813\n",
      "Epoch [1/10], Batch [70/201], Loss: 0.8894\n",
      "Epoch [1/10], Batch [80/201], Loss: 0.8163\n",
      "Epoch [1/10], Batch [90/201], Loss: 0.7676\n",
      "Epoch [1/10], Batch [100/201], Loss: 0.5901\n",
      "Epoch [1/10], Batch [110/201], Loss: 0.6428\n",
      "Epoch [1/10], Batch [120/201], Loss: 0.6871\n",
      "Epoch [1/10], Batch [130/201], Loss: 0.4570\n",
      "Epoch [1/10], Batch [140/201], Loss: 0.6431\n",
      "Epoch [1/10], Batch [150/201], Loss: 0.5475\n",
      "Epoch [1/10], Batch [160/201], Loss: 0.7041\n",
      "Epoch [1/10], Batch [170/201], Loss: 0.7616\n",
      "Epoch [1/10], Batch [180/201], Loss: 0.7120\n",
      "Epoch [1/10], Batch [190/201], Loss: 0.6253\n",
      "Epoch [1/10], Batch [200/201], Loss: 0.4236\n",
      "\n",
      "Epoch [1/10]\n",
      "Train Loss: 0.0001 | Val Loss: 0.4483 | Val Acc: 78.60%\n",
      "Epoch [2/10], Batch [10/201], Loss: 0.3759\n",
      "Epoch [2/10], Batch [20/201], Loss: 0.5473\n",
      "Epoch [2/10], Batch [30/201], Loss: 0.4494\n",
      "Epoch [2/10], Batch [40/201], Loss: 0.6416\n",
      "Epoch [2/10], Batch [50/201], Loss: 0.4037\n",
      "Epoch [2/10], Batch [60/201], Loss: 0.3084\n",
      "Epoch [2/10], Batch [70/201], Loss: 0.2948\n",
      "Epoch [2/10], Batch [80/201], Loss: 0.3301\n",
      "Epoch [2/10], Batch [90/201], Loss: 0.3375\n",
      "Epoch [2/10], Batch [100/201], Loss: 0.3552\n",
      "Epoch [2/10], Batch [110/201], Loss: 0.2999\n",
      "Epoch [2/10], Batch [120/201], Loss: 0.2421\n",
      "Epoch [2/10], Batch [130/201], Loss: 0.3683\n",
      "Epoch [2/10], Batch [140/201], Loss: 0.3269\n",
      "Epoch [2/10], Batch [150/201], Loss: 0.3176\n",
      "Epoch [2/10], Batch [160/201], Loss: 0.3683\n",
      "Epoch [2/10], Batch [170/201], Loss: 0.3144\n",
      "Epoch [2/10], Batch [180/201], Loss: 0.3133\n",
      "Epoch [2/10], Batch [190/201], Loss: 0.4584\n",
      "Epoch [2/10], Batch [200/201], Loss: 0.4250\n",
      "\n",
      "Epoch [2/10]\n",
      "Train Loss: 0.0014 | Val Loss: 0.2966 | Val Acc: 85.80%\n",
      "Epoch [3/10], Batch [10/201], Loss: 0.2538\n",
      "Epoch [3/10], Batch [20/201], Loss: 0.1499\n",
      "Epoch [3/10], Batch [30/201], Loss: 0.3853\n",
      "Epoch [3/10], Batch [40/201], Loss: 0.1701\n",
      "Epoch [3/10], Batch [50/201], Loss: 0.2836\n",
      "Epoch [3/10], Batch [60/201], Loss: 0.2438\n",
      "Epoch [3/10], Batch [70/201], Loss: 0.2046\n",
      "Epoch [3/10], Batch [80/201], Loss: 0.1778\n",
      "Epoch [3/10], Batch [90/201], Loss: 0.1849\n",
      "Epoch [3/10], Batch [100/201], Loss: 0.1153\n",
      "Epoch [3/10], Batch [110/201], Loss: 0.1118\n",
      "Epoch [3/10], Batch [120/201], Loss: 0.1332\n",
      "Epoch [3/10], Batch [130/201], Loss: 0.2229\n",
      "Epoch [3/10], Batch [140/201], Loss: 0.1837\n",
      "Epoch [3/10], Batch [150/201], Loss: 0.2048\n",
      "Epoch [3/10], Batch [160/201], Loss: 0.2173\n",
      "Epoch [3/10], Batch [170/201], Loss: 0.1607\n",
      "Epoch [3/10], Batch [180/201], Loss: 0.0932\n",
      "Epoch [3/10], Batch [190/201], Loss: 0.1271\n",
      "Epoch [3/10], Batch [200/201], Loss: 0.1254\n",
      "\n",
      "Epoch [3/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.2725 | Val Acc: 91.20%\n",
      "Epoch [4/10], Batch [10/201], Loss: 0.0637\n",
      "Epoch [4/10], Batch [20/201], Loss: 0.0581\n",
      "Epoch [4/10], Batch [30/201], Loss: 0.0314\n",
      "Epoch [4/10], Batch [40/201], Loss: 0.0556\n",
      "Epoch [4/10], Batch [50/201], Loss: 0.0414\n",
      "Epoch [4/10], Batch [60/201], Loss: 0.0468\n",
      "Epoch [4/10], Batch [70/201], Loss: 0.0626\n",
      "Epoch [4/10], Batch [80/201], Loss: 0.0642\n",
      "Epoch [4/10], Batch [90/201], Loss: 0.0600\n",
      "Epoch [4/10], Batch [100/201], Loss: 0.1106\n",
      "Epoch [4/10], Batch [110/201], Loss: 0.0702\n",
      "Epoch [4/10], Batch [120/201], Loss: 0.1583\n",
      "Epoch [4/10], Batch [130/201], Loss: 0.0784\n",
      "Epoch [4/10], Batch [140/201], Loss: 0.0434\n",
      "Epoch [4/10], Batch [150/201], Loss: 0.0798\n",
      "Epoch [4/10], Batch [160/201], Loss: 0.1147\n",
      "Epoch [4/10], Batch [170/201], Loss: 0.0801\n",
      "Epoch [4/10], Batch [180/201], Loss: 0.1350\n",
      "Epoch [4/10], Batch [190/201], Loss: 0.1470\n",
      "Epoch [4/10], Batch [200/201], Loss: 0.0934\n",
      "\n",
      "Epoch [4/10]\n",
      "Train Loss: 0.0001 | Val Loss: 0.2851 | Val Acc: 91.20%\n",
      "Epoch [5/10], Batch [10/201], Loss: 0.0732\n",
      "Epoch [5/10], Batch [20/201], Loss: 0.0488\n",
      "Epoch [5/10], Batch [30/201], Loss: 0.1477\n",
      "Epoch [5/10], Batch [40/201], Loss: 0.1376\n",
      "Epoch [5/10], Batch [50/201], Loss: 0.0306\n",
      "Epoch [5/10], Batch [60/201], Loss: 0.1515\n",
      "Epoch [5/10], Batch [70/201], Loss: 0.0579\n",
      "Epoch [5/10], Batch [80/201], Loss: 0.1510\n",
      "Epoch [5/10], Batch [90/201], Loss: 0.0949\n",
      "Epoch [5/10], Batch [100/201], Loss: 0.0872\n",
      "Epoch [5/10], Batch [110/201], Loss: 0.0584\n",
      "Epoch [5/10], Batch [120/201], Loss: 0.1231\n",
      "Epoch [5/10], Batch [130/201], Loss: 0.1826\n",
      "Epoch [5/10], Batch [140/201], Loss: 0.3057\n",
      "Epoch [5/10], Batch [150/201], Loss: 0.0778\n",
      "Epoch [5/10], Batch [160/201], Loss: 0.1894\n",
      "Epoch [5/10], Batch [170/201], Loss: 0.1937\n",
      "Epoch [5/10], Batch [180/201], Loss: 0.0313\n",
      "Epoch [5/10], Batch [190/201], Loss: 0.0977\n",
      "Epoch [5/10], Batch [200/201], Loss: 0.2005\n",
      "\n",
      "Epoch [5/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.2326 | Val Acc: 93.80%\n",
      "Epoch [6/10], Batch [10/201], Loss: 0.0465\n",
      "Epoch [6/10], Batch [20/201], Loss: 0.0531\n",
      "Epoch [6/10], Batch [30/201], Loss: 0.0157\n",
      "Epoch [6/10], Batch [40/201], Loss: 0.0318\n",
      "Epoch [6/10], Batch [50/201], Loss: 0.0183\n",
      "Epoch [6/10], Batch [60/201], Loss: 0.1734\n",
      "Epoch [6/10], Batch [70/201], Loss: 0.0968\n",
      "Epoch [6/10], Batch [80/201], Loss: 0.0861\n",
      "Epoch [6/10], Batch [90/201], Loss: 0.0790\n",
      "Epoch [6/10], Batch [100/201], Loss: 0.1116\n",
      "Epoch [6/10], Batch [110/201], Loss: 0.0528\n",
      "Epoch [6/10], Batch [120/201], Loss: 0.0104\n",
      "Epoch [6/10], Batch [130/201], Loss: 0.0498\n",
      "Epoch [6/10], Batch [140/201], Loss: 0.0238\n",
      "Epoch [6/10], Batch [150/201], Loss: 0.0290\n",
      "Epoch [6/10], Batch [160/201], Loss: 0.0210\n",
      "Epoch [6/10], Batch [170/201], Loss: 0.0795\n",
      "Epoch [6/10], Batch [180/201], Loss: 0.0390\n",
      "Epoch [6/10], Batch [190/201], Loss: 0.0370\n",
      "Epoch [6/10], Batch [200/201], Loss: 0.0187\n",
      "\n",
      "Epoch [6/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.2604 | Val Acc: 95.00%\n",
      "Epoch [7/10], Batch [10/201], Loss: 0.0197\n",
      "Epoch [7/10], Batch [20/201], Loss: 0.0774\n",
      "Epoch [7/10], Batch [30/201], Loss: 0.0112\n",
      "Epoch [7/10], Batch [40/201], Loss: 0.0432\n",
      "Epoch [7/10], Batch [50/201], Loss: 0.0263\n",
      "Epoch [7/10], Batch [60/201], Loss: 0.0140\n",
      "Epoch [7/10], Batch [70/201], Loss: 0.0068\n",
      "Epoch [7/10], Batch [80/201], Loss: 0.0477\n",
      "Epoch [7/10], Batch [90/201], Loss: 0.0395\n",
      "Epoch [7/10], Batch [100/201], Loss: 0.0033\n",
      "Epoch [7/10], Batch [110/201], Loss: 0.0495\n",
      "Epoch [7/10], Batch [120/201], Loss: 0.0104\n",
      "Epoch [7/10], Batch [130/201], Loss: 0.0446\n",
      "Epoch [7/10], Batch [140/201], Loss: 0.0103\n",
      "Epoch [7/10], Batch [150/201], Loss: 0.0151\n",
      "Epoch [7/10], Batch [160/201], Loss: 0.0141\n",
      "Epoch [7/10], Batch [170/201], Loss: 0.0271\n",
      "Epoch [7/10], Batch [180/201], Loss: 0.0033\n",
      "Epoch [7/10], Batch [190/201], Loss: 0.0357\n",
      "Epoch [7/10], Batch [200/201], Loss: 0.0820\n",
      "\n",
      "Epoch [7/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.3895 | Val Acc: 90.00%\n",
      "Epoch [8/10], Batch [10/201], Loss: 0.0302\n",
      "Epoch [8/10], Batch [20/201], Loss: 0.0087\n",
      "Epoch [8/10], Batch [30/201], Loss: 0.0402\n",
      "Epoch [8/10], Batch [40/201], Loss: 0.0304\n",
      "Epoch [8/10], Batch [50/201], Loss: 0.0018\n",
      "Epoch [8/10], Batch [60/201], Loss: 0.0048\n",
      "Epoch [8/10], Batch [70/201], Loss: 0.0191\n",
      "Epoch [8/10], Batch [80/201], Loss: 0.0163\n",
      "Epoch [8/10], Batch [90/201], Loss: 0.0074\n",
      "Epoch [8/10], Batch [100/201], Loss: 0.0304\n",
      "Epoch [8/10], Batch [110/201], Loss: 0.0867\n",
      "Epoch [8/10], Batch [120/201], Loss: 0.0291\n",
      "Epoch [8/10], Batch [130/201], Loss: 0.0119\n",
      "Epoch [8/10], Batch [140/201], Loss: 0.0037\n",
      "Epoch [8/10], Batch [150/201], Loss: 0.0877\n",
      "Epoch [8/10], Batch [160/201], Loss: 0.0446\n",
      "Epoch [8/10], Batch [170/201], Loss: 0.1081\n",
      "Epoch [8/10], Batch [180/201], Loss: 0.1281\n",
      "Epoch [8/10], Batch [190/201], Loss: 0.0075\n",
      "Epoch [8/10], Batch [200/201], Loss: 0.0097\n",
      "\n",
      "Epoch [8/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.2178 | Val Acc: 95.80%\n",
      "Epoch [9/10], Batch [10/201], Loss: 0.0054\n",
      "Epoch [9/10], Batch [20/201], Loss: 0.0004\n",
      "Epoch [9/10], Batch [30/201], Loss: 0.0166\n",
      "Epoch [9/10], Batch [40/201], Loss: 0.0045\n",
      "Epoch [9/10], Batch [50/201], Loss: 0.0046\n",
      "Epoch [9/10], Batch [60/201], Loss: 0.0333\n",
      "Epoch [9/10], Batch [70/201], Loss: 0.0109\n",
      "Epoch [9/10], Batch [80/201], Loss: 0.0062\n",
      "Epoch [9/10], Batch [90/201], Loss: 0.0150\n",
      "Epoch [9/10], Batch [100/201], Loss: 0.0721\n",
      "Epoch [9/10], Batch [110/201], Loss: 0.0377\n",
      "Epoch [9/10], Batch [120/201], Loss: 0.0879\n",
      "Epoch [9/10], Batch [130/201], Loss: 0.0294\n",
      "Epoch [9/10], Batch [140/201], Loss: 0.0510\n",
      "Epoch [9/10], Batch [150/201], Loss: 0.0409\n",
      "Epoch [9/10], Batch [160/201], Loss: 0.0180\n",
      "Epoch [9/10], Batch [170/201], Loss: 0.1210\n",
      "Epoch [9/10], Batch [180/201], Loss: 0.1029\n",
      "Epoch [9/10], Batch [190/201], Loss: 0.0233\n",
      "Epoch [9/10], Batch [200/201], Loss: 0.0017\n",
      "\n",
      "Epoch [9/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.1621 | Val Acc: 95.60%\n",
      "Epoch [10/10], Batch [10/201], Loss: 0.0316\n",
      "Epoch [10/10], Batch [20/201], Loss: 0.0506\n",
      "Epoch [10/10], Batch [30/201], Loss: 0.0021\n",
      "Epoch [10/10], Batch [40/201], Loss: 0.0078\n",
      "Epoch [10/10], Batch [50/201], Loss: 0.0224\n",
      "Epoch [10/10], Batch [60/201], Loss: 0.0225\n",
      "Epoch [10/10], Batch [70/201], Loss: 0.0032\n",
      "Epoch [10/10], Batch [80/201], Loss: 0.0022\n",
      "Epoch [10/10], Batch [90/201], Loss: 0.0310\n",
      "Epoch [10/10], Batch [100/201], Loss: 0.0110\n",
      "Epoch [10/10], Batch [110/201], Loss: 0.0013\n",
      "Epoch [10/10], Batch [120/201], Loss: 0.0003\n",
      "Epoch [10/10], Batch [130/201], Loss: 0.0012\n",
      "Epoch [10/10], Batch [140/201], Loss: 0.0027\n",
      "Epoch [10/10], Batch [150/201], Loss: 0.0009\n",
      "Epoch [10/10], Batch [160/201], Loss: 0.0022\n",
      "Epoch [10/10], Batch [170/201], Loss: 0.0033\n",
      "Epoch [10/10], Batch [180/201], Loss: 0.0032\n",
      "Epoch [10/10], Batch [190/201], Loss: 0.0194\n",
      "Epoch [10/10], Batch [200/201], Loss: 0.0960\n",
      "\n",
      "Epoch [10/10]\n",
      "Train Loss: 0.0000 | Val Loss: 0.6673 | Val Acc: 85.00%\n",
      "\n",
      "Training selesai! Akurasi validasi terbaik: 95.80%\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = ResidualVGG16(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "best_val_acc = 0.0  # Untuk menyimpan akurasi terbaik\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    total_batches = len(train_loader)\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            current_loss = running_loss / 10\n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], '\n",
    "                  f'Batch [{batch_idx+1}/{total_batches}], '\n",
    "                  f'Loss: {current_loss:.4f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    print(f'\\nEpoch [{epoch+1}/{NUM_EPOCHS}]')\n",
    "    print(f'Train Loss: {train_loss:.4f} | '\n",
    "          f'Val Loss: {val_loss:.4f} | '\n",
    "          f'Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print(f'\\nTraining selesai! Akurasi validasi terbaik: {best_val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb6382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea03fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7245889,
     "sourceId": 11555904,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
